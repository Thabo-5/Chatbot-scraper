{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\piala\\anaconda3\\lib\\site-packages (0.5.23)\n",
      "Requirement already satisfied: Wand in c:\\users\\piala\\anaconda3\\lib\\site-packages (from pdfplumber) (0.6.3)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in c:\\users\\piala\\anaconda3\\lib\\site-packages (from pdfplumber) (7.1.2)\n",
      "Requirement already satisfied: pdfminer.six==20200517 in c:\\users\\piala\\anaconda3\\lib\\site-packages (from pdfplumber) (20200517)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\piala\\anaconda3\\lib\\site-packages (from pdfminer.six==20200517->pdfplumber) (2.1.0)\n",
      "Requirement already satisfied: pycryptodome in c:\\users\\piala\\anaconda3\\lib\\site-packages (from pdfminer.six==20200517->pdfplumber) (3.9.8)\n",
      "Requirement already satisfied: chardet; python_version > \"3.0\" in c:\\users\\piala\\anaconda3\\lib\\site-packages (from pdfminer.six==20200517->pdfplumber) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open website home page\n",
    "\n",
    "URL = 'https://explore-datascience.net/'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Extract all urls from the website page\n",
    "\n",
    "def get_urls(soup):\n",
    "    \"\"\"\n",
    "    Function returns a list of all url links from a BeautifulSoup object.\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "    for link in soup.find_all('a'):\n",
    "        if link.get('href') != None:\n",
    "            urls.append(link.get('href'))\n",
    "    urls = [x for x in urls if 'https' in x]\n",
    "    urls = list(set(urls))\n",
    "    return urls\n",
    "\n",
    "urls_list = get_urls(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def website_links(urls_list):\n",
    "    urls = [x for x in urls_list if '.pdf' not in x and 'facebook' not in x and 'twitter' not in x and 'linkedin' not in x]\n",
    "    pdfs = [x for x in urls_list if '.pdf' in x]\n",
    "    new_urls = []\n",
    "    for i in range(len(urls)):\n",
    "        page = requests.get(urls[i])\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        pg_urls = get_urls(soup)\n",
    "        if len(pg_urls) > 0:\n",
    "            pdfs.extend([x for x in pg_urls if '.pdf' in x and x not in pdfs])\n",
    "            new_urls.extend([x for x in pg_urls if x not in urls \n",
    "                             and x not in new_urls \n",
    "                             and x not in pdfs \n",
    "                             and 'https://explore-datascience.net' in x])\n",
    "    urls.extend(new_urls)\n",
    "    return urls, len(new_urls), pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all urls and pdfs from the website.\n",
    "\n",
    "urls, new_urls, pdfs = website_links(urls_list)\n",
    "if new_urls > 0:\n",
    "    urls, new_urls, pdfs = website_links(urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://explore-datascience.net/course/info/1/3',\n",
       " 'https://explore-datascience.net/alumni/hire-explorer',\n",
       " 'https://explore-datascience.net/course/info/40/5/online',\n",
       " 'https://explore-datascience.net/course/info/4/3',\n",
       " 'https://explore-datascience.net/course/info/53/5/online',\n",
       " 'https://explore-datascience.net/course/info/4/3/1',\n",
       " 'https://explore-datascience.net/',\n",
       " 'https://explore-datascience.net/course/info/39/5/online',\n",
       " 'https://explore-datascience.net/enterprise/summary',\n",
       " 'https://explore-datascience.net/course/info/41/5/online',\n",
       " 'https://explore-datascience.net/course/info/42/5/online',\n",
       " 'https://explore-datascience.net/about-us/our-values',\n",
       " 'https://explore-datascience.net/course/info/1/3/1',\n",
       " 'https://explore-datascience.net/course/info/34/3/online',\n",
       " 'https://explore-datascience.net/course/info/35/4',\n",
       " 'https://explore-datascience.net/course/info/43/5/online',\n",
       " 'https://explore-datascience.net/course/info/4/3/online',\n",
       " 'https://explore-datascience.net/course/info/3/3/1',\n",
       " 'https://explore-datascience.net/contact',\n",
       " 'https://explore-datascience.net/course/info/1/3/online',\n",
       " 'https://explore-datascience.net/course/info/34/3',\n",
       " 'https://explore-datascience.net/about-us/our-courses',\n",
       " 'https://explore-datascience.net/course/info/3/3',\n",
       " 'https://explore-datascience.net/course/info/3/3/online',\n",
       " 'https://explore-datascience.net/course/info/34/3/1',\n",
       " 'https://explore-datascience.net/course/info/38/5/online',\n",
       " 'https://explore-datascience.net/course/info/2/4',\n",
       " 'https://explore-datascience.net/alumni/student-reviews',\n",
       " 'https://explore-datascience.net/enterprise/build-pipeline',\n",
       " 'https://explore-datascience.net/login',\n",
       " 'https://explore-datascience.net/course/info/1/3/oncampus',\n",
       " 'https://explore-datascience.net/course/info/8/4',\n",
       " 'https://explore-datascience.net/course/info/39/5',\n",
       " 'https://explore-datascience.net/course/info/43/5',\n",
       " 'https://explore-datascience.net/course/info/40/5',\n",
       " 'https://explore-datascience.net/course/info/38/5',\n",
       " 'https://explore-datascience.net/course/info/41/5',\n",
       " 'https://explore-datascience.net/course/info/42/5',\n",
       " 'https://explore-datascience.net/signup',\n",
       " 'https://explore-datascience.net/password']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed explore_course_info_1_3: 1 of 40\n",
      "Completed explore_alumni_hire-explorer: 2 of 40\n",
      "Completed explore_course_info_40_5_online: 3 of 40\n",
      "Completed explore_course_info_4_3: 4 of 40\n",
      "Completed explore_course_info_53_5_online: 5 of 40\n",
      "Completed explore_course_info_4_3_1: 6 of 40\n",
      "Completed explore_: 7 of 40\n",
      "Completed explore_course_info_39_5_online: 8 of 40\n",
      "Completed explore_enterprise_summary: 9 of 40\n",
      "Completed explore_course_info_41_5_online: 10 of 40\n",
      "Completed explore_course_info_42_5_online: 11 of 40\n",
      "Completed explore_about-us_our-values: 12 of 40\n",
      "Completed explore_course_info_1_3_1: 13 of 40\n",
      "Completed explore_course_info_34_3_online: 14 of 40\n",
      "Completed explore_course_info_35_4: 15 of 40\n",
      "Completed explore_course_info_43_5_online: 16 of 40\n",
      "Completed explore_course_info_4_3_online: 17 of 40\n",
      "Completed explore_course_info_3_3_1: 18 of 40\n",
      "Completed explore_contact: 19 of 40\n",
      "Completed explore_course_info_1_3_online: 20 of 40\n",
      "Completed explore_course_info_34_3: 21 of 40\n",
      "Completed explore_about-us_our-courses: 22 of 40\n",
      "Completed explore_course_info_3_3: 23 of 40\n",
      "Completed explore_course_info_3_3_online: 24 of 40\n",
      "Completed explore_course_info_34_3_1: 25 of 40\n",
      "Completed explore_course_info_38_5_online: 26 of 40\n",
      "Completed explore_course_info_2_4: 27 of 40\n",
      "Completed explore_alumni_student-reviews: 28 of 40\n",
      "Completed explore_enterprise_build-pipeline: 29 of 40\n",
      "Completed explore_login: 30 of 40\n",
      "Completed explore_course_info_1_3_oncampus: 31 of 40\n",
      "Completed explore_course_info_8_4: 32 of 40\n",
      "Completed explore_course_info_39_5: 33 of 40\n",
      "Completed explore_course_info_43_5: 34 of 40\n",
      "Completed explore_course_info_40_5: 35 of 40\n",
      "Completed explore_course_info_38_5: 36 of 40\n",
      "Completed explore_course_info_41_5: 37 of 40\n",
      "Completed explore_course_info_42_5: 38 of 40\n",
      "Completed explore_signup: 39 of 40\n",
      "Completed explore_password: 40 of 40\n"
     ]
    }
   ],
   "source": [
    "# Scrape text data from the website (this excludes the pdfs)\n",
    "\n",
    "for i in range(len(urls)):\n",
    "    page = requests.get(urls[i])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    name = str(urls[i]).replace('https://explore-datascience.net', 'explore').replace('/', '_')\n",
    "    f = open(\"{}.txt\".format(name), \"a+\", encoding=\"utf-8\")\n",
    "    f.write('{}\\n'.format(str(urls[i])))\n",
    "    for items in soup.find_all():\n",
    "        all_text = [item.text for item in items.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'a', 'p'])]\n",
    "        for j in all_text:\n",
    "            f.write('{}\\n'.format(j))\n",
    "    f.close()\n",
    "    print('Completed {0}: {1} of {2}'.format(name, i+1, len(urls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://explore-datascience.net/pdf/Data Science 2021 (1).pdf\n",
      "https://explore-datascience.net/pdf/Visualisation Prospectus 2020.pdf\n",
      "https://explore-datascience.net/pdf/Data Analytics 2021 (1).pdf\n",
      "https://explore-datascience.net/pdf/Introduction to Data Science Prospectus 2021 [v1.0].pdf\n",
      "https://explore-datascience.net/pdf/Python for Data Science Prospectus 2020.pdf\n",
      "https://explore-datascience.net/pdf/Business Intelligence 2021 (1).pdf\n",
      "https://explore-datascience.net/pdf/Data Visualisation Prospectus 2020.pdf\n",
      "https://explore-datascience.net/pdf/Data Engineering 2021 (1).pdf\n",
      "https://explore-datascience.net/pdf/SQL Prospectus 2020.pdf\n",
      "https://explore-datascience.net/pdf/Machine Learning Prospectus 2020.pdf\n"
     ]
    }
   ],
   "source": [
    "for i in pdfs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = ['https://explore-datascience.net/pdf/EDSA_Course_Outline.pdf?12.4',\n",
    " 'https://explore-datascience.net/pdf/Data_Analytics.pdf',\n",
    " 'https://explore-datascience.net/pdf/EDSA_Course_Outline.pdf',\n",
    " 'https://explore-datascience.net/pdf/Data_Science.pdf',\n",
    " 'https://explore-datascience.net/pdf/Full_Syllbus_DS_for_Executives_Mar_2020.pdf',\n",
    " 'https://explore-datascience.net/pdf/Machine_Learning_Analysts_Short.pdf',\n",
    " 'https://explore-datascience.net/pdf/careers/Senior_Data_Scientist.pdf',\n",
    " 'https://explore-datascience.net/pdf/careers/Senior_Data_Engineer.pdf',\n",
    " 'https://explore-datascience.net/pdf/Machine_Learning_for_Analysts.pdf',\n",
    " 'https://explore-datascience.net/pdf/Data_Engineering.pdf',\n",
    " 'https://explore-datascience.net/pdf/Full_Syllbus_DS_for_Managers_Mar_2020.pdf',\n",
    " 'https://explore-datascience.net/pdf/Data_Science_Managers_Short.pdf',\n",
    " 'https://explore-datascience.net/pdf/Advanced_Python_Short.pdf',\n",
    " 'https://explore-datascience.net/pdf/Explore_Course_Catalogue.pdf',\n",
    " 'https://explore-datascience.net/pdf/Advanced_Visualisation_Short.pdf',\n",
    " 'https://explore-datascience.net/pdf/Data_Science_High_School_Short.pdf',\n",
    " #'https://explore-datascience.net/pdf/aws_cloud_practitioner_short.pdf',\n",
    " 'https://explore-datascience.net/pdf/Deep_Learning_AI.pdf',\n",
    " 'https://explore-datascience.net/pdf/Insights_Led_Organisation.pdf',\n",
    " 'https://explore-datascience.net/pdf/How to Structure Your Data Science Capability.pdf',\n",
    " 'https://explore-datascience.net/pdf/Investing_in_LandD.pdf',\n",
    " 'https://explore-datascience.net/pdf/A Data Science Team.pdf',\n",
    " 'https://explore-datascience.net/pdf/Ogranization_Data_Maturity.pdf',\n",
    " 'https://explore-datascience.net/pdf/Machine_Learning_for_Analysts_Short.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDSA_Course_Outline\n",
      "Data_Analytics\n",
      "EDSA_Course_Outline\n",
      "Data_Science\n",
      "Full_Syllbus_DS_for_Executives_Mar_2020\n",
      "Machine_Learning_Analysts_Short\n",
      "Senior_Data_Scientist\n",
      "Senior_Data_Engineer\n",
      "Machine_Learning_for_Analysts\n",
      "Data_Engineering\n",
      "Full_Syllbus_DS_for_Managers_Mar_2020\n",
      "Data_Science_Managers_Short\n",
      "Advanced_Python_Short\n",
      "Explore_Course_Catalogue\n",
      "Advanced_Visualisation_Short\n",
      "Data_Science_High_School_Short\n",
      "Deep_Learning_AI\n",
      "Insights_Led_Organisation\n",
      "How to Structure Your Data Science Capability\n",
      "Investing_in_LandD\n",
      "A Data Science Team\n",
      "Ogranization_Data_Maturity\n",
      "Machine_Learning_for_Analysts_Short\n"
     ]
    }
   ],
   "source": [
    "# Scrape text data from the PDFs\n",
    "for i in pdfs:\n",
    "    rq = requests.get(i)\n",
    "    pdf = pdfplumber.open(BytesIO(rq.content))\n",
    "    name = \"\".join(re.findall(r'pdf/(.*?).pdf', str(i)))\n",
    "    name = name.replace('careers/', '')\n",
    "    myfile = io.open(name + \".txt\", \"w\", encoding=\"utf-8\")\n",
    "    for i in range(len(pdf.pages)):\n",
    "        p = pdf.pages[i]\n",
    "        text = p.extract_text()\n",
    "        myfile.write(str(text)+\"\\n \")\n",
    "    myfile.close()\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
